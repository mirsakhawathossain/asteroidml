{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/5b/cd32bb85651eccebfb489cc6ef7f060ce0f62350a6239127e398313090cc/openml-0.10.2.tar.gz (158kB)\n",
      "\u001b[K    100% |################################| 163kB 4.6MB/s \n",
      "\u001b[?25hCollecting liac-arff>=2.4.0 (from openml)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/35/fbc9217cfa91d98888b43e1a19c03a50d716108c58494c558c65e308f372/liac-arff-2.4.0.tar.gz\n",
      "Collecting xmltodict (from openml)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (2.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (2.7.3)\n",
      "Requirement already satisfied: pandas>=0.19.2 in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.6.2 in /home/idies/miniconda3/lib/python3.6/site-packages (from openml) (1.15.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/idies/miniconda3/lib/python3.6/site-packages (from requests->openml) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/idies/miniconda3/lib/python3.6/site-packages (from requests->openml) (2.7)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /home/idies/miniconda3/lib/python3.6/site-packages (from requests->openml) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/idies/miniconda3/lib/python3.6/site-packages (from requests->openml) (2018.10.15)\n",
      "Requirement already satisfied: six>=1.5 in /home/idies/miniconda3/lib/python3.6/site-packages (from python-dateutil->openml) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/idies/miniconda3/lib/python3.6/site-packages (from pandas>=0.19.2->openml) (2018.5)\n",
      "Building wheels for collected packages: openml, liac-arff\n",
      "  Running setup.py bdist_wheel for openml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/idies/.cache/pip/wheels/71/ec/5f/aaad9e184680b0b8f1a02ff0ec640cace5adf5bff7bb0af1b4\n",
      "  Running setup.py bdist_wheel for liac-arff ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/idies/.cache/pip/wheels/d1/6a/e7/529dc54d76ecede4346164a09ae3168df358945612710f5203\n",
      "Successfully built openml liac-arff\n",
      "Installing collected packages: liac-arff, xmltodict, openml\n",
      "Successfully installed liac-arff-2.4.0 openml-0.10.2 xmltodict-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pha-ml'...\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 17 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (17/17), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://gitlab.com/mirsakhawathossain/pha-ml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "\n",
    "openml.config.start_using_configuration_for_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = 'ba071d55fd6b48f947739f6348b55039'\n",
    "openml.config.server ='https://www.openml.org/api/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenML Dataset\n",
      "==============\n",
      "Name..........: Asteroid_Dataset\n",
      "Version.......: 1\n",
      "Format........: arff\n",
      "Upload Date...: 2020-02-16 12:21:29\n",
      "Licence.......: Public\n",
      "Download URL..: https://www.openml.org/data/v1/download/21799723/Asteroid_Dataset.arff\n",
      "OpenML URL....: https://www.openml.org/d/42252\n",
      "# of features.: 35\n",
      "# of instances: 126131\n"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(42252)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = openml.tasks.list_tasks(task_type_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tid', 'ttid', 'did', 'name', 'task_type', 'status',\n",
      "       'estimation_procedure', 'evaluation_measures', 'source_data',\n",
      "       'target_feature', 'MajorityClassSize', 'MaxNominalAttDistinctValues',\n",
      "       'MinorityClassSize', 'NumberOfClasses', 'NumberOfFeatures',\n",
      "       'NumberOfInstances', 'NumberOfInstancesWithMissingValues',\n",
      "       'NumberOfMissingValues', 'NumberOfNumericFeatures',\n",
      "       'NumberOfSymbolicFeatures', 'cost_matrix'],\n",
      "      dtype='object')\n",
      "First 5 of 3308 tasks:\n",
      "   tid  ttid  did        name                  task_type  status  \\\n",
      "2    2     1    2      anneal  Supervised Classification  active   \n",
      "3    3     1    3    kr-vs-kp  Supervised Classification  active   \n",
      "4    4     1    4       labor  Supervised Classification  active   \n",
      "5    5     1    5  arrhythmia  Supervised Classification  active   \n",
      "6    6     1    6      letter  Supervised Classification  active   \n",
      "\n",
      "      estimation_procedure  evaluation_measures source_data target_feature  \\\n",
      "2  10-fold Crossvalidation  predictive_accuracy           2          class   \n",
      "3  10-fold Crossvalidation                  NaN           3          class   \n",
      "4  10-fold Crossvalidation  predictive_accuracy           4          class   \n",
      "5  10-fold Crossvalidation  predictive_accuracy           5          class   \n",
      "6  10-fold Crossvalidation                  NaN           6          class   \n",
      "\n",
      "      ...       MaxNominalAttDistinctValues  MinorityClassSize  \\\n",
      "2     ...                               7.0                8.0   \n",
      "3     ...                               3.0             1527.0   \n",
      "4     ...                               3.0               20.0   \n",
      "5     ...                              13.0                2.0   \n",
      "6     ...                              26.0              734.0   \n",
      "\n",
      "   NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\n",
      "2              5.0              39.0              898.0   \n",
      "3              2.0              37.0             3196.0   \n",
      "4              2.0              17.0               57.0   \n",
      "5             13.0             280.0              452.0   \n",
      "6             26.0              17.0            20000.0   \n",
      "\n",
      "   NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\n",
      "2                               898.0                22175.0   \n",
      "3                                 0.0                    0.0   \n",
      "4                                56.0                  326.0   \n",
      "5                               384.0                  408.0   \n",
      "6                                 0.0                    0.0   \n",
      "\n",
      "   NumberOfNumericFeatures  NumberOfSymbolicFeatures  cost_matrix  \n",
      "2                      6.0                      33.0          NaN  \n",
      "3                      0.0                      37.0          NaN  \n",
      "4                      8.0                       9.0          NaN  \n",
      "5                    206.0                      74.0          NaN  \n",
      "6                     16.0                       1.0          NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "   tid  ttid  did        name                  task_type  status  \\\n",
      "2    2     1    2      anneal  Supervised Classification  active   \n",
      "3    3     1    3    kr-vs-kp  Supervised Classification  active   \n",
      "4    4     1    4       labor  Supervised Classification  active   \n",
      "5    5     1    5  arrhythmia  Supervised Classification  active   \n",
      "6    6     1    6      letter  Supervised Classification  active   \n",
      "\n",
      "      estimation_procedure  evaluation_measures source_data target_feature  \\\n",
      "2  10-fold Crossvalidation  predictive_accuracy           2          class   \n",
      "3  10-fold Crossvalidation                  NaN           3          class   \n",
      "4  10-fold Crossvalidation  predictive_accuracy           4          class   \n",
      "5  10-fold Crossvalidation  predictive_accuracy           5          class   \n",
      "6  10-fold Crossvalidation                  NaN           6          class   \n",
      "\n",
      "      ...       MaxNominalAttDistinctValues  MinorityClassSize  \\\n",
      "2     ...                               7.0                8.0   \n",
      "3     ...                               3.0             1527.0   \n",
      "4     ...                               3.0               20.0   \n",
      "5     ...                              13.0                2.0   \n",
      "6     ...                              26.0              734.0   \n",
      "\n",
      "   NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\n",
      "2              5.0              39.0              898.0   \n",
      "3              2.0              37.0             3196.0   \n",
      "4              2.0              17.0               57.0   \n",
      "5             13.0             280.0              452.0   \n",
      "6             26.0              17.0            20000.0   \n",
      "\n",
      "   NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\n",
      "2                               898.0                22175.0   \n",
      "3                                 0.0                    0.0   \n",
      "4                                56.0                  326.0   \n",
      "5                               384.0                  408.0   \n",
      "6                                 0.0                    0.0   \n",
      "\n",
      "   NumberOfNumericFeatures  NumberOfSymbolicFeatures  cost_matrix  \n",
      "2                      6.0                      33.0          NaN  \n",
      "3                      0.0                      37.0          NaN  \n",
      "4                      8.0                       9.0          NaN  \n",
      "5                    206.0                      74.0          NaN  \n",
      "6                     16.0                       1.0          NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "tasks = pd.DataFrame.from_dict(tasks, orient='index')\n",
    "print(tasks.columns)\n",
    "print(f\"First 5 of {len(tasks)} tasks:\")\n",
    "print(tasks.head())\n",
    "\n",
    "# As conversion to a pandas dataframe is a common task, we have added this functionality to the\n",
    "# OpenML-Python library which can be used by passing ``output_format='dataframe'``:\n",
    "tasks_df = openml.tasks.list_tasks(task_type_id=1, output_format='dataframe')\n",
    "print(tasks_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 of 1 tasks:\n",
      "           tid  ttid    did              name                  task_type  \\\n",
      "211687  211687     1  42252  Asteroid_Dataset  Supervised Classification   \n",
      "\n",
      "        status     estimation_procedure  evaluation_measures source_data  \\\n",
      "211687  active  10-fold Crossvalidation  predictive_accuracy       42252   \n",
      "\n",
      "       target_feature  MajorityClassSize  MinorityClassSize  NumberOfClasses  \\\n",
      "211687            pha             125975                156                2   \n",
      "\n",
      "        NumberOfFeatures  NumberOfInstances  \\\n",
      "211687                34             126131   \n",
      "\n",
      "        NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\n",
      "211687                                  96                     99   \n",
      "\n",
      "        NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n",
      "211687                       31                         2  \n"
     ]
    }
   ],
   "source": [
    "tasks = openml.tasks.list_tasks(data_id=42252, output_format='dataframe')\n",
    "print(f\"First 5 of {len(tasks)} tasks:\")\n",
    "print(tasks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 211687\n",
    "task = openml.tasks.get_task(task_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats, n_folds, n_samples = task.get_split_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 211687: number of repeats: 1, number of folds: 10, number of samples 1.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Task {}: number of repeats: {}, number of folds: {}, number of samples {}.'.format(\n",
    "        task_id, n_repeats, n_folds, n_samples,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113517,) int32\n",
      "(12614,) int32\n"
     ]
    }
   ],
   "source": [
    "train_indices, test_indices = task.get_train_test_split_indices(\n",
    "    repeat=0,\n",
    "    fold=0,\n",
    "    sample=0,\n",
    ")\n",
    "\n",
    "print(train_indices.shape, train_indices.dtype)\n",
    "print(test_indices.shape, test_indices.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (113518, 33), y_train.shape: (113518,), X_test.shape: (12613, 33), y_test.shape: (12613,)\n"
     ]
    }
   ],
   "source": [
    "X, y, _, _ = task.get_dataset().get_data(task.target_name)\n",
    "X_train = X.loc[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X.loc[test_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "print(\n",
    "    'X_train.shape: {}, y_train.shape: {}, X_test.shape: {}, y_test.shape: {}'.format(\n",
    "        X_train.shape, y_train.shape, X_test.shape, y_test.shape,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 211687: number of repeats: 1, number of folds: 10, number of samples 1.\n"
     ]
    }
   ],
   "source": [
    "task_id = 211687\n",
    "task = openml.tasks.get_task(task_id)\n",
    "n_repeats, n_folds, n_samples = task.get_split_dimensions()\n",
    "print(\n",
    "    'Task {}: number of repeats: {}, number of folds: {}, number of samples {}.'.format(\n",
    "        task_id, n_repeats, n_folds, n_samples,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat #0, fold #0, samples 0: X_train.shape: (113517, 33), y_train.shape (113517,), X_test.shape (12614, 33), y_test.shape (12614,)\n",
      "Repeat #0, fold #1, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #2, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #3, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #4, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #5, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #6, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #7, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #8, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #9, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n"
     ]
    }
   ],
   "source": [
    "for repeat_idx in range(n_repeats):\n",
    "    for fold_idx in range(n_folds):\n",
    "        for sample_idx in range(n_samples):\n",
    "            train_indices, test_indices = task.get_train_test_split_indices(\n",
    "                repeat=repeat_idx,\n",
    "                fold=fold_idx,\n",
    "                sample=sample_idx,\n",
    "            )\n",
    "            X_train = X.loc[train_indices]\n",
    "            y_train = y[train_indices]\n",
    "            X_test = X.loc[test_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            print(\n",
    "                'Repeat #{}, fold #{}, samples {}: X_train.shape: {}, '\n",
    "                'y_train.shape {}, X_test.shape {}, y_test.shape {}'.format(\n",
    "                    repeat_idx, fold_idx, sample_idx, X_train.shape, y_train.shape, X_test.shape,\n",
    "                    y_test.shape,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 211687: number of repeats: 1, number of folds: 10, number of samples 1.\n"
     ]
    }
   ],
   "source": [
    "task_id = 211687\n",
    "task = openml.tasks.get_task(task_id)\n",
    "n_repeats, n_folds, n_samples = task.get_split_dimensions()\n",
    "print(\n",
    "    'Task {}: number of repeats: {}, number of folds: {}, number of samples {}.'.format(\n",
    "        task_id, n_repeats, n_folds, n_samples,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat #0, fold #0, samples 0: X_train.shape: (113517, 33), y_train.shape (113517,), X_test.shape (12614, 33), y_test.shape (12614,)\n",
      "Repeat #0, fold #1, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #2, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #3, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #4, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #5, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #6, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #7, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #8, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #9, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n"
     ]
    }
   ],
   "source": [
    "for repeat_idx in range(n_repeats):\n",
    "    for fold_idx in range(n_folds):\n",
    "        for sample_idx in range(n_samples):\n",
    "            train_indices, test_indices = task.get_train_test_split_indices(\n",
    "                repeat=repeat_idx,\n",
    "                fold=fold_idx,\n",
    "                sample=sample_idx,\n",
    "            )\n",
    "            X_train = X.loc[train_indices]\n",
    "            y_train = y[train_indices]\n",
    "            X_test = X.loc[test_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            print(\n",
    "                'Repeat #{}, fold #{}, samples {}: X_train.shape: {}, '\n",
    "                'y_train.shape {}, X_test.shape {}, y_test.shape {}'.format(\n",
    "                    repeat_idx, fold_idx, sample_idx, X_train.shape, y_train.shape, X_test.shape,\n",
    "                    y_test.shape,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 211687: number of repeats: 1, number of folds: 10, number of samples 1.\n"
     ]
    }
   ],
   "source": [
    "task_id = 211687\n",
    "task = openml.tasks.get_task(task_id)\n",
    "n_repeats, n_folds, n_samples = task.get_split_dimensions()\n",
    "print(\n",
    "    'Task {}: number of repeats: {}, number of folds: {}, number of samples {}.'.format(\n",
    "        task_id, n_repeats, n_folds, n_samples,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat #0, fold #0, samples 0: X_train.shape: (113517, 33), y_train.shape (113517,), X_test.shape (12614, 33), y_test.shape (12614,)\n",
      "Repeat #0, fold #1, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #2, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #3, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #4, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #5, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #6, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #7, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #8, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n",
      "Repeat #0, fold #9, samples 0: X_train.shape: (113518, 33), y_train.shape (113518,), X_test.shape (12613, 33), y_test.shape (12613,)\n"
     ]
    }
   ],
   "source": [
    "for repeat_idx in range(n_repeats):\n",
    "    for fold_idx in range(n_folds):\n",
    "        for sample_idx in range(n_samples):\n",
    "            train_indices, test_indices = task.get_train_test_split_indices(\n",
    "                repeat=repeat_idx,\n",
    "                fold=fold_idx,\n",
    "                sample=sample_idx,\n",
    "            )\n",
    "            X_train = X.loc[train_indices]\n",
    "            y_train = y[train_indices]\n",
    "            X_test = X.loc[test_indices]\n",
    "            y_test = y[test_indices]\n",
    "\n",
    "            print(\n",
    "                'Repeat #{}, fold #{}, samples {}: X_train.shape: {}, '\n",
    "                'y_train.shape {}, X_test.shape {}, y_test.shape {}'.format(\n",
    "                    repeat_idx, fold_idx, sample_idx, X_train.shape, y_train.shape, X_test.shape,\n",
    "                    y_test.shape,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'OMB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d05650b5ed8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \"\"\"\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'OMB'"
     ]
    }
   ],
   "source": [
    "#### openml.config.start_using_configuration_for_example()\n",
    "\n",
    "# NOTE: We are using dataset 20 from the test server: https://test.openml.org/d/20\n",
    "dataset = openml.datasets.get_dataset(42252)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format='dataframe',\n",
    "    target=dataset.default_target_attribute\n",
    ")\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
